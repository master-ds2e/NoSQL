{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic storage format for unstructured data.\n",
    "\n",
    "The first thing to do before thinking about how to store unstructured data is to understand the differences between structured and unstructured data. \n",
    "\n",
    "## Structured vs Unstructured vs Semi-structured.\n",
    "\n",
    "Structured Data:\n",
    "- Row and column format (or can be easily converted to row and column)\n",
    "- Fixed length/width\n",
    "- Missing values = Blank\n",
    "- Storing tools: CSV, TXT, XLS.\n",
    "\n",
    "Semi-Structured or Unstructured Data:\n",
    "- Contains tags, keys or other markers.\n",
    "- Nested or hierarchical data.\n",
    "- Avoid messy translations into a relational data mode.\n",
    "- storing tools: JSON, XML, HTML, Pickle.\n",
    "\n",
    "N.B: Unstructured Data might be an abuse of language. Every data is structured in some way or your computer would not be able to understand it. Data is atleast semi-structured. Information in the other hand... An image has structured date (pixel by pixel, author, date, type,...) but the information present on an image is unstructured (The computer does not understand that on the image there's a \"red car\", as an observer you structure this information by gathering the pixel and the information becomes structured)\n",
    "\n",
    "## Text\n",
    "\n",
    "Strings are the main sources of semi-structured data. Hence emails, logs, words document, ... are all considered unstructured-data.  \n",
    "\n",
    "To have a persistant storage of text you can use a .txt file, logs, ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple example of insert in a txt.file\n",
    "\n",
    "import tqdm\n",
    "\n",
    "# tqdm for monitoring the loop\n",
    "for i in tqdm.tqdm(range(10000)):\n",
    "    # with open to avoid the open followed by closed\n",
    "    # a+ = append and if file does not exists create it !\n",
    "    with open('data/Chap1/example1.txt', 'a+') as f:\n",
    "        # write in the txt file the str i and skip a line\n",
    "        f.write(str(i) + \"\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dict\n",
    "\n",
    "A dictionary is a collection which is unordered, mutable and indexed (i.e it stores semi-structured data). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dict format in python {key:value} the value can be a list or a dict. \n",
    "# key must be a str avoid the use of \".\" in key\n",
    "\n",
    "paper = {\"authors\" : [\"Auteur1\",\"Auteur2\",\"Auteur3\"],\n",
    "         \"title\" : \"This is paper 1\",\n",
    "         \"affiliations\" : [\"University of Mannheim\",\"University of Strasbourg\"],\n",
    "         \"ref\" : [\"This is ref 1\",\"This is ref 2\",\"This is ref 3\"]}\n",
    "print(paper)\n",
    "print(type(paper))\n",
    "print(dir(paper))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's multiple options to save a dict. Below is one of these option using the JSON format.\n",
    "What exactly is JavaScript Object Notation (JSON) ?\n",
    "\n",
    "\"JSON is an open standard file format, and data interchange format, that uses human-readable text to store and transmit data objects consisting of attributeâ€“value pairs and array data types.\" wikipedia\n",
    "\n",
    "Two important things from this definition: attribute-value pairs and human-readable text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON\n",
    "# Same syntax as txt file except with use json.dump and json.load instead of write and read\n",
    "\n",
    "import json\n",
    "with open('data/Chap1/data.json', 'w') as fp:\n",
    "    json.dump(paper, fp)\n",
    "    \n",
    "with open('data/Chap1/data.json', 'r') as fp:\n",
    "    test= json.load(fp)\n",
    "\n",
    "print(test)\n",
    "print(type(test))\n",
    "print(dir(test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuing to work on JSON data but with a dataset from [here](https://data.world/doc/commerce-enterprise-data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRUD operations on JSON\n",
    "\n",
    "# READ\n",
    "import json\n",
    "with open('data/Chap1/data_world.json', 'r', encoding= \"utf-8\") as fp:\n",
    "    docs = json.load(fp)\n",
    "    \n",
    "print(docs[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update\n",
    "import tqdm\n",
    "\n",
    "for doc in tqdm.tqdm(docs):\n",
    "    if doc[\"publisher\"][\"@type\"] == \"org:Organization\":\n",
    "        doc['title'] = \"Hello world\"\n",
    "\n",
    "print(docs[1])\n",
    "\n",
    "\"\"\"\n",
    "with open('data/Chap1/data.json', 'w') as fp:\n",
    "    json.dump(paper, fp)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete\n",
    "\n",
    "[doc.pop(\"title\") for doc in docs if doc[\"publisher\"][\"@type\"] == \"org:Organization\"]\n",
    "\n",
    "print(docs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JSON comes as an alternative to XML. \"Extensible Markup Language (XML) is a markup language that defines a set of rules for encoding documents in a format that is both human-readable and machine-readable.\". My recommandation: use JSON. However if you encounter an XML file in your line of work here's how you can work with it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XML, Extensible Markup Language. tree-like structure.\n",
    "# Multiple package to work with python and xml: lxml, xml.dom.minidom, xml.etree.ElementTree\n",
    "# We will use lxml but make sure to look at the docs of others.\n",
    "\n",
    "import lxml.etree\n",
    "\n",
    "# Load the data\n",
    "xml_file = \"data/Chap1/xml_file.nxml\"\n",
    "root = lxml.etree.parse(xml_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prettify = Make it human readable\n",
    "print(lxml.etree.tostring(root, encoding=\"unicode\", pretty_print=True)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Some explanation on the xml format\n",
    "\n",
    "xml format: <TAG1 ATTRIBUTE1><TAG2 ATTRIBUTE2> TEXT </ENDTAG2></ENDTAG1>\n",
    "TAG2 is a children node of TAG1\n",
    "read more about it here https://www.w3schools.com/html/html_elements.asp\n",
    "\n",
    "To access elements we use something called XPATH\n",
    "xpath(\"//TAG1[ATTRIBUTE1='something']/TAG2[ATTRIBUTE2='something']/text()\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract = root.xpath(\"//abstract//text()\")\n",
    "body = root.xpath(\"//body//text()\")\n",
    "title = root.xpath(\"//title-group//text()\")\n",
    "figures = root.xpath(\"//fig//text()\")\n",
    "\n",
    "aff = root.xpath(\"//aff/text()\")\n",
    "aff = [i for i in aff if not i.startswith((' ', '\\t'))]\n",
    "aff_label = root.xpath(\"//aff/label/text()\")\n",
    "\n",
    "mails =root.xpath(\"//author-notes/corresp\")[0]\n",
    "mails.getchildren()\n",
    "\n",
    "print(abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xref = {}\n",
    "for affiliation,label in zip(aff,aff_label):\n",
    "    xref[label]= affiliation\n",
    "\n",
    "authors = root.xpath(\"//contrib\")\n",
    "authors = [i.getchildren() for i in authors]\n",
    "for author in authors:\n",
    "    names = [i.getchildren() for i in author if i.tag == \"name\"][0]\n",
    "    surname = [i.text for i in names if i.tag==\"surname\"]\n",
    "    name = [i.text for i in names if i.tag==\"given-names\"]\n",
    "    xrefs = [i.text for i in author if i.tag==\"xref\"]\n",
    "    print(name,surname,xref[xrefs[0]],xrefs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sound and Image\n",
    "\n",
    "Working with sound is out of the scope of this course but they are an important source of unstructured data (self-driving cars, Google image, Youtube, Twitch, ...). You already know the persistent storage for sound and music (png, jpg, wav, mp3, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "im = Image.open(requests.get(\"https://www.actuia.com/wp-content/uploads/2020/09/BETA-Logo.png\", stream=True).raw)\n",
    "im.save(\"data/Chap1/image_beta.png\", \"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plays a sine wave sound, code from https://realpython.com/playing-and-recording-sound-python/\n",
    "\n",
    "import numpy as np\n",
    "import simpleaudio as sa\n",
    "\n",
    "frequency = 440  # Our played note will be 440 Hz\n",
    "fs = 44100  # 44100 samples per second\n",
    "seconds = 3  # Note duration of 3 seconds\n",
    "\n",
    "# Generate array with seconds*sample_rate steps, ranging between 0 and seconds\n",
    "t = np.linspace(0, seconds, seconds * fs, False)\n",
    "\n",
    "# Generate a 440 Hz sine wave\n",
    "note = np.sin(frequency * t * 2 * np.pi)\n",
    "\n",
    "# Ensure that highest value is in 16-bit range\n",
    "audio = note * (2**15 - 1) / np.max(np.abs(note))\n",
    "# Convert to 16-bit data\n",
    "audio = audio.astype(np.int16)\n",
    "\n",
    "# Start playback\n",
    "play_obj = sa.play_buffer(audio, 1, 2, fs)\n",
    "\n",
    "# Wait for playback to finish before exiting\n",
    "play_obj.wait_done()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale it up\n",
    "\n",
    "Now imagine you have huge amount of semi-structured data in form of a dict. For example you can request 30M tweets with the name of the person who tweeted, the text, the date, the language, the comments,...\n",
    "\n",
    "You could store it in a JSON or a Pickle file. Problem arise when you try to open it back. You maybe don't want to load every tweets in your memory (RAM and time issues) but with these format there's no other choices. Maybe you also want to store this 30M on an other machine and connect to it from a small laptop. All of this shows you the limitation of storing semi-structured data.\n",
    "\n",
    "As for the structured format where you went from csv to SQL DBs you can also go from JSON to noSQL DBs. That's what MongoDB is and we will learn to use it in the next chapter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary\n",
    "\n",
    "Before going in more depth between the different types of NoSQL DBs we will talk a bit about the vocabulary used in the Databases context. Don't worry you do not need to know all of them by heart or understand everything at this point but when you encounter them later you can come back here if needed:\n",
    "\n",
    "- Persistent storage: \"a system that outlives (persists more than) the process that created it\" wikipedia. You create a Python object, say a list or a dict, when you close the Python session you lose this object. In other words it's not persistent. Before closing it you save this item as a pickle or .txt file: it becomes persistent. \n",
    "- CRUD: Create Read Update Delete (CRUD) are the most basic operations you can perform on persistent storage. For example in a txt file you can append new observations, read already existing ones but also update and delete specific row (last two operation are a bit tedious in a simple .txt file but effortles on DBs)\n",
    "- Database transaction: Sum of operations done in one go, the bank exemple is often used. First you debit an account (1st operation) then you credit the other account (2nd operation). The whole is a transaction.\n",
    "- Distributed data store: Data are stored on different node (computers if you want), if one node is down you can still access your data on other nodes (You usually put Replica Sets on different nodes)\n",
    "- ACID: \n",
    "    - Atomicity, either every operations in the transaction is complete or none. \n",
    "    - Consistency, DBs live on a set of rules (Primary Key, Constraints,...). At the end of the transactions theses rules are still respected\n",
    "    - Isolation, in the context of concurrent transaction the result is the same as sequential transactions.\n",
    "    - Durability, once a transaction is committed it becomes persistant.  \n",
    "\n",
    "Read more about ACID compliance and NoSQL ([1](https://dba.stackexchange.com/questions/185763/why-are-nosql-databases-not-acid-compliant),[2](https://stackoverflow.com/questions/2608103/is-there-any-nosql-data-store-that-is-acid-compliant))\n",
    "\n",
    "- CAP theorem: Consistency, Availability and Partition tolerance. \"it is impossible for a distributed data store to simultaneously provide more than two out of the following three guarantees\" wikipedia.\n",
    "\n",
    "Read more on the CAP theorem ([1](https://en.wikipedia.org/wiki/CAP_theorem),[2](https://www.bmc.com/blogs/cap-theorem/))\n",
    "\n",
    "Not a set-in-stone list, might update it later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NoSQL types\n",
    "\n",
    "Multiple types of NoSQL DB exist. The most popular are written below\n",
    "\n",
    "- Key-value stores \n",
    "- Document stores \n",
    "- Wide column stores\n",
    "- Graph databases "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key-value stores\n",
    "\n",
    "A key-value store is the simplest possible data model: it's a storage system that stores values indexed by a key (kinda like a dict). The key is generaly an id, identifier or a primary key and the value associated is a binary object, the system does not really handle the value (blackbox). CRUD operations does exist on key-value stores.\n",
    "\n",
    "pros: scalable and fast\n",
    "\n",
    "cons: for simple data and simple queries (query limited on key since values are black-box)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document stores\n",
    "\n",
    "A document-oriented database extends the key-values model in the sense that values are stored in a structured format called document that the database can understand (i.e it's no longer a blackbox). Therefore you are no longer limited in the queries and you can perform CRUD operations on keys but also values. This allows the user to fetch entire page of information (for example blogs that contain a specific keyword) and is much more appreciated by websites storing a lot of informations.\n",
    "The structure of a document stores: DB-collection-Document. \n",
    "\n",
    "pros: Extension of key-value (value examinable), complex query.\n",
    "\n",
    "cons: Slow for updating (not a problem as long you can have your index in RAM), difficult to query when keys are constantly changing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wide column store\n",
    "\n",
    "\"It uses tables, rows, and columns, but unlike a relational database, the names and format of the columns can vary from row to row in the same table\" (wikipedia) i.e it's more flexible than the typical SQL DB but it's not the only difference. In some wide column DB you need to specify fields (cassandra) others you don't. CRUD operations available. Read by rows (a key is assigned to each row)\n",
    "\n",
    "pros: works well with flat data with similar scheme\n",
    "cons: No complex query (Average, sum,...), hard to change the structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph DBs\n",
    "\n",
    "DB that consists of nodes (individuals/agent) which are connected by edges (relation between the two individuals). Each node and edge have proprety (e.g individuals has different characteristics and they are connected in a certain way defined by the property)\n",
    "\n",
    "pros and cons can be resumed by the fact that they are specific to graph data and nothing else.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sum up\n",
    "\n",
    "Read more about types of NoSQL DB here https://www.ksi.mff.cuni.cz/~svoboda/courses/2016-2-MIE-PDB/lectures/Lecture-06-NoSQL.pdf.\n",
    "\n",
    "Refer to this website if you are interested in seeing the most used db knowing each type. https://db-engines.com/en/ranking\n",
    "\n",
    "- key-value: #1 ranked is Redis\n",
    "- Document-oriented: #1 is MongoDB\n",
    "- Wide columns: #1 is Cassandra\n",
    "- Graph: #1 is Neo4j\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "**TODO 1**: Lorem Ipsum is just a random txt that devs use as a placeholder for multiple things (especially web developping) when you don't have the real text and just want to test your functionnality. Put a [Lorem Ipsum](https://www.lipsum.com/) of 3 paragraphs in a txt file using python, each paragraph delimited by two new line.\n",
    "\n",
    "**TODO 2**: Create a dict from the paper of [lecun et al.](https://www.researchgate.net/publication/277411157_Deep_Learning) and [goodfellow et al.](https://arxiv.org/abs/1406.2661) with authors, title, affiliations.\n",
    "\n",
    "**TODO 3**: Save the previously created dict in the JSON format and load it back.\n",
    "\n",
    "**TODO 4**: Save the previously created dict in the pickle format. Try to open manually (i.e without python), is it human readable ?\n",
    "\n",
    "**TODO 5**: Parse the xml_file2 in the same way as seen in the lecture: put infos in a dict and save it in a json file.\n",
    "\n",
    "**TODO 6**: Download an image of your choice and save it in either jpg or png.\n",
    "\n",
    "**TODO 7**: From the data/Chap1/data_world.json file, create a set of publisher type.\n",
    "\n",
    "**TODO 8**: \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
